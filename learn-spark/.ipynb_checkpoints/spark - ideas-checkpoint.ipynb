{
 "metadata": {
  "name": "",
  "signature": "sha256:a2b81f64e165058871c5e97deba6f4a272d1908713670d68e66c536c8d6615fc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Spark is a distributed computing framework, which is built on top of some ideas such as ClusterManager (ResourceManager), applications, tasks and etc.\n",
      "- Distributed computing is usually across a cluster by (1) requesting resources and (2) scheduling tasks, which can be done via a uniform interface called **ClusterManager**. Examples are [yarn](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html) (hadoop, mapr, ec2) and [Mesos](http://mesos.apache.org/)\n",
      "- References:\n",
      "    - [Spark 1.1.1 Cluster Mode Overview](http://spark.apache.org/docs/latest/cluster-overview.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}